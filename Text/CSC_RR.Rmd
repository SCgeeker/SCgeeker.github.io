How Registered Reports Turn Bad Sciences Good?
========================================================
author: Sau-Chin Chen, Tzu-Chi University & Erasmus University Rotterdam
date: 2016/10/16  
width: 1024
height: 960
transition: zoom
navigation: none


Take Home Messages
========================================================
![hypothetico-deductive model](20140102-1.jpg)  
<small>Hypothetico-deductive model of the scientific method. by Chambers, Feredoes, Muthukumaraswamy, and Etchells(2014)</small>
***
![empirical cycle](524px-Empirical_Cycle.png)  
<small>By Empirical_Cycle.png: TesseUndDaan derivative work: Beao (Empirical_Cycle.png) [CC BY 3.0 (http://creativecommons.org/licenses/by/3.0)], via Wikimedia Commons</small>

References
========================================================
1. Chambers, C. D., Feredoes, E., Muthukumaraswamy, S. D., & Etchells, P. J. (2014). Instead of "playing the game" it is time to change the rules: Registered Reports at AIMS Neuroscience and beyond. *AIMS Environmental Science, 1,* 4-17. [doi](http://doi.org/10.3934/Neuroscience.2014.1.4)
2. Wagenmakers, E.-J., Wetzels, R., Borsboom, D., Maas, H. L. J. van der, & Kievit, R. A. (2012). An Agenda for Purely Confirmatory Research. *Perspectives on Psychological Science, 7,* 632-638. [doi](http://doi.org/10.1177/1745691612463078)
3. de Groot, A. D. (2014). The meaning of "significance" for different types of research [translated and annotated by Eric-Jan Wagenmakers, Denny Borsboom, Josine Verhagen, Rogier Kievit, Marjan Bakker, Angelique Cramer, Dora Matzke, Don Mellenbergh, and Han L. J. van der Maas]. *Acta Psychologica, 148C,* 188-194. [doi](http://doi.org/10.1016/j.actpsy.2014.02.001)

class Sciences("Bad"):
========================================================
<img src="Hypothetico_deductive_Sci_Meth.png" alt="hypothetico-deductive model" style="width: 850px;"/>  
Bad factors hidden in Hypothetico-Deductive Model (Remake by [COS](http://cos.io), 2014)

def Statistical Power("Low"):
========================================================
<img src="BHWM_F1.large.jpg" alt="Estimated powers lower than true powers" style="width: 800px;"/>  
<small>[Bakker, Hartgerink, Wicherts, and Maas (2016)](http://pss.sagepub.com/content/27/8/1069)</small>

def p-hacking("significance"):
========================================================
![](significant_U.png)
</br>
[Simonsohn, Nelson, and Simmons, (2014, p535)](http://doi.apa.org/getdoi.cfm?doi=10.1037/a0033242):"...  a statistically significant finding may reflect selective reporting rather than a true effect."
***
![](significant_D.png)  
<small>by [xkcd](https://xkcd.com/)(CC BY-NC 2.5)</small>

Simulating p-hacking
========================================================
<img src="2015Fig01.jpg" alt="The difficulty of p-hacking beyond p < .05" style="width: 1200px;"/>
<small>[Simonsohn, Simmons, & Nelson (2015)](http://doi.apa.org/getdoi.cfm?doi=10.1037/xge0000104)</small>

def Effect Size("Publication bias", "Statistical Power"):
========================================================
incremental: true
```{r EPUB, echo=FALSE,  message=FALSE, warning=FALSE}
m1 <- 0  # mu H0
sd1 <- 1.5 # sigma H0
m2 <- 3.5 # mu HA
sd2 <- 1.5 # sigma HA

z_crit <- qnorm(1-(0.05/2), m1, sd1)

# set length of tails
min1 <- m1-sd1*4
max1 <- m1+sd1*4
min2 <- m2-sd2*4
max2 <- m2+sd2*4          
# create x sequence
x <- seq(min(min1,min2), max(max1, max2), .01)
# generate normal dist #1
y1 <- dnorm(x, m1, sd1)
# put in data frame
df1 <- data.frame("x" = x, "y" = y1)
# generate normal dist #2
y2 <- dnorm(x, m2, sd2)
# put in data frame
df2 <- data.frame("x" = x, "y" = y2)

# Alpha polygon
y.poly <- pmin(y1,y2)
poly1 <- data.frame(x=x, y=y.poly)
poly1 <- poly1[poly1$x >= z_crit, ] 
poly1<-rbind(poly1, c(z_crit, 0))  # add lower-left corner

# Beta polygon
poly2 <- df2
poly2 <- poly2[poly2$x <= z_crit,] 
poly2<-rbind(poly2, c(z_crit, 0))  # add lower-left corner

# power polygon; 1-beta
poly3 <- df2
poly3 <- poly3[poly3$x >= z_crit,] 
poly3 <-rbind(poly3, c(z_crit, 0))  # add lower-left corner

# combine polygons. 
poly1$id <- 3 # alpha, give it the highest number to make it the top layer
poly2$id <- 2 # beta
poly3$id <- 1 # power; 1 - beta
poly <- rbind(poly1, poly2, poly3)
poly$id <- factor(poly$id,  labels=c("power","beta","alpha"))

plot.new()
plot.window(xlim=range(x), ylim=c(-0.1,0.3))
# add polygons
polygon(poly3,  density=10) # 1-beta
polygon(poly2, density=3, angle=-45, lty="dashed") # beta
polygon(poly1, density=10, angle=0) # alpha
# add h_a dist
lines(df2,lwd=3)
# add h_0 dist
lines(df1,lwd=3)
# Critical Value
lines(data.frame(x=rep(z_crit,2),y=c(0,max(df1$y) + 0.05)), lty=1)
# center of H0
lines(data.frame(x=c(0,0),y=c(0,max(df1$y))), lty="dashed")
# center of H1
lines(data.frame(x=rep(m2,2),y=c(0,max(df2$y))), lty="dashed")
### annotations
# h_0 title
text(m1, 0.3, expression(H[0]), cex=1.5)
# h_1 title
text(m2, 0.3, expression(H[1]), cex=1.5)
# beta annotation
## arrows(x0=-1, y0=0.045, x1=1, y1=0.01,lwd=2,length=0.15)
text(z_crit - 0.8, 0.045, expression(beta), cex=1.5)
# alpha annotation
## arrows(x0=4, y0=-0.01, x1=3.5, y1=0.01, lwd=2, length=0.15)
text(x=z_crit + 0.32, y=0.01, expression(alpha), cex=1.5, col = "blue")
# 1-beta 
## arrows(x0=6, y0=0.15, x1=5, y1=0.1, lwd=2,length=0.15)
text(x=z_crit + 1, y=0.135, expression(1-beta), cex=1.5)
# expected effect size
text(x=m2, y= -0.01, expression(d), cex=1.5)
# Actual effect size
arrows(x0=m2 + 0.4, y0=-0.035, x1=m2 + 0.4, y1=0, lwd=2, length=0.15,col = "red")
text(x=m2 + 0.4, y= -0.05, expression(D), cex=1.5, col = "red")

# show z_crit; start of rejection region
## abline(v=z_crit)
# add bottom line
abline(h=0)
## title("Statistical Power")
```
<small>[Nuijten et al. (2015)](http://psycnet.apa.org/doi/10.1037/gpr0000034) Figure 1 Remake</small>
***
- d =  Expected effect size  
- <font color = "red">D</font> = Actual effect size because of publication bias
- <font color = "red">D</font> - d = Relative bias on the effect size.
- $$ Relative\ bias = \frac{1 - pub}{1 + pub \frac{\beta}{1 - \beta}} $$
- Meta analysis on <font color = "red">D</font> will have a overesitmated effect size.

def Effect Size("Publication bias", "Statistical Power"):
========================================================
- Sample size is smaller, publication bias is bigger.
<img src="Figure-2-The-effect-of-publication-bias-and-population-effect-size-Cohen's-d-on-the.png" alt="sample size X publication bias" style="width: 1200px;"/>  
Nuijten et al. (2015) Figure 2

def HARKing:
========================================================
- **Hypothesizing After the Results are Known**(Kerr, 1998)
<img src="HARKing.png" alt="Survey on 156 scholars of social psychology, clinical/community psychology, and sociology. Many expect more H-D and inspiration than HARKing, but their observations and suspect every approach have the equal frequencies." style="width: 1200px;"/>  
[John et al. (2012)](http://pss.sagepub.com/content/early/2012/04/16/0956797611430953) Figure 1


def Replication( ):
========================================================
incremental: true 
- Direct Replication: Repeat the original experimental procedure as exact as possible.

- Conceptual Replication: Repeat the test of a hypotheis or experimental results in use of different methods.

- During 1900 to 2011, there are 1.6%(5,051 out of 321,411) of psychological papers mentioned **replication**[(Makel, Plucker & Hegarty, 2012)](http://pps.sagepub.com/content/7/6/537.abstract).


def Replication( ):
========================================================
<small>More conceptual replications than direct replications(Makel, Plucker & Hegarty, 2012)</small>
<img src="ReplicationT1.gif" alt="Replication Types" style="width: 1200px;"/>  

========================================================
title:false
# Why psycholgists do not like Replication?

empirical Cycle: From Exploratory to Confirmatory
========================================================
incremental: true
![empirical cycle](Empirical_Cycle.png)  
by [Adrianus Dingeman de Groot (1956, 2014)](https://nl.wikipedia.org/wiki/Adriaan_de_Groot)
***
- **Exploratory**(*Generating Hypothesis*): Observation -> Induction -> Deduction -> *[1 or more testable hypothesis; [Jerzy Neyman's view](https://static.jasp-stats.org/presentations/August2015/RM/#7 )]*
- **Confirmatory**(*Testing Hypothesis*): *[testable hypothesis; [Ronald Fisher's view](https://static.jasp-stats.org/presentations/August2015/RM/#8)]* -> Testing -> Evaluation
- *New hypotheis could bring new findings.*
- Psychologisits have prefered **Exploratory** than **Confirmatory**.
- Hypothetico-Deductive Model is for testing hypothesis rather than generating hypothesis. 

========================================================
title: false
# Hypothetico-Deductive Model is for testing hypothesis rather than generating hypothesis.

========================================================
title: false
![](WWBMK_F1.large.jpg)  
<small>Wagenmakers, Wetzels, Borsboom, Maas, and Kievit (2012) Figure 1</small>

Why Sciences being Bad?
========================================================
```{r eval=FALSE}
class Testing("Generating"):  
    def Statistical Power:  
        "no matter how low it is"
    def p value:
        "smaller is better"
    def Conclusion:
        if ture:
            "Take the words form my proposal"
        else:
            "Take the words from SPSS sheet"
    def Publication:
        "Paper is everything!"
    def Replication:
        "Inedible!"
```

========================================================
title:false
# Good Sciences need not only **Exploratory Research** but also **Confirmatory Research**


Solution: Registered Research(RR)
========================================================
# It has to be **Confirmatory Research**

Am I conducting a Confirmatory Research?
========================================================
## Organize your proposal in [AsPredicted](https://aspredicted.org/) format.

RR workflow
========================================================
<img src="401-2791-1-PB.jpg" alt="RR workflow" style="width: 1400px;"/>  
<small>King, M., Dablander, F., Jakob, L., Agan, M., Huber, F., Haslbeck, J., & Brecht, K. (2016). Registered Reports for Student Research. Journal of European Psychology Students, 7. doi:10.5334/jeps.401</small>

Why Sciences being Good?
========================================================
```{r eval=FALSE}
class Testing("Protocol", "IPA"):  
    def Statistical Power("Protocol"):  
        pilots("data1", "data2",...)
    def significance("Protocol"):
        methods("between_group", "within_group", ...)
    def Conclusion("Protocol"):
        if match:
            Rule.1
        else:
            Rule.2
    def Data_Collection("Protocol"):
        if "IPA" is true:
            "Do as protocol"
    def Replication:
        if "IPA" is true:
            Open("materials", "analysis scripts", ...)
```


Registered Replication Research(RRR)
========================================================
- Aims to **Capstone Studies**
    - High citations
    - Lack of direct replications
    - Meta analysis shows **publication bias**
- Multiple branches: [APS RRR](http://scchen.com/Text/text_2016004/)
    - Leading Lab manages the protocol
    - Collobrative Labs start to collect data after IPA
    - Leading Lab is going to finish Stage 2

Original Registered Research
========================================================
- One topic, one lab, one branch
- Idea to complete the empirical cycle
    - [Klauer, Becker, & Spruyt, (2016)](http://econtent.hogrefe.com/doi/10.1027/1618-3169/a000286): a failed replication
    - [Domachowska et al. (2016)](http://www.sciencedirect.com/science/article/pii/S0022103115001055): a successful replication
- Supports
    - Journals call for registered research:
        - [Experimental Psychology](https://us.hogrefe.com/products/journals/exppsy)
        - [AIMS Neuroscience](http://www.aimspress.com/news/160.html)
        - [More...](https://osf.io/8mpji/wiki/home/?_ga=1.248873159.1782532904.1473762292)
    - Funding and Awards
        - [Preregistration Challenge](https://cos.io/prereg/)
        - [Replication Studies pilot from NWO](http://www.nwo.nl/en/news-and-events/news/2016/nwo-makes-3-million-available-for-replication-studies-pilot.html)

Obstacles
========================================================
incremental: true
- No new findings
    - Are we struggling in Neyman's view?
- More writings
- Fears to open
- Authority worship

Suggestions
========================================================
incremental: true
- Thinking your research project in the **empirical cycle**.
- Change from the beginning: Restate PSY101, Stat101, ...
- Apply RR workflow to the production of dissertations, the grant applications , etc.

========================================================
title: true
![](captain-america-civil-war-02082016-182755.png)  
To be Continued...